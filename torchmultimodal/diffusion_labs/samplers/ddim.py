# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

from typing import Dict, Generator, Iterable, Optional, Union

import torch
from torch import nn, Tensor
from torchmultimodal.diffusion_labs.predictors.predictor import Predictor
from torchmultimodal.diffusion_labs.samplers.sampler import Sampler
from torchmultimodal.diffusion_labs.schedules.discrete_gaussian_schedule import (
    DiscreteGaussianSchedule,
)
from torchmultimodal.diffusion_labs.utils.common import DiffusionOutput


class DDIModule(nn.Module, Sampler):
    """
    DDIModule implements "Denoising Diffusion Implicit Models" presented by Song et. al
    (https://arxiv.org/abs/2010.02502).

    DDIMs are a class of iterative implicit probabilistic models that has the same
    training procedure as DDPMs, but can produce high quality samples much faster.
    Song et. al propose a new generative process where given a noisy x_t, we first
    make a prediction for x_0, and we then use it to obtain a sample for x_{tâˆ’1}.
    DDIMs are known to be effective in generating high quality samples faster than
    DDPMs.

    Example:
        ddim_model = DDPModule(model, schedule, predictor)
        prediction_t = ddim_model(x_t, t)

        ddim_model.eval()
        x_0 = ddim_model(x_T, T)

    Code ref:
    https://github.com/openai/improved-diffusion/blob/main/improved_diffusion/gaussian_diffusion.py

    Attributes:
    model (nn.Module):
    schedule (DiscreteGaussianSchedule): defines noise diffusion throughout time
    predictor (Predictor): used to help predict x0
    eval_steps (Tensor): a subset of steps to sample at inference time
    eta (float): scaling factor used in Equation 12 of Song et. al
                    (https://arxiv.org/abs/2010.02502)
    Args:
        x (Tensor): corrupted data at time t (when t = schedule.steps, x is fully noise)
                     of shape  [b, c, ...]
        timestep (Tensor): diffusion step
        conditional_inputs (Dict): dictionary of context embeddings

    """

    def __init__(
        self,
        model: nn.Module,
        schedule: DiscreteGaussianSchedule,
        predictor: Predictor,
        eval_steps: Optional[Tensor] = None,
        progress_bar: bool = True,
        eta: float = 1.0,
    ):
        super().__init__()
        torch._C._log_api_usage_once(f"torchmultimodal.{self.__class__.__name__}")

        self.model = model
        self.schedule = schedule
        self.predictor = predictor
        self.progress_bar = progress_bar
        self.eta = eta

        if eval_steps is None:
            eval_steps = torch.arange(self.schedule.steps)
        else:
            eval_steps, _ = eval_steps.sort()

        self.eval_steps: Tensor
        self.register_buffer("eval_steps", eval_steps.to(torch.long))

    def remove_noise(
        self,
        xt: Tensor,
        c: Optional[Dict[str, Tensor]],
        cur_step: Tensor,
        next_step: Tensor,
    ) -> Tensor:
        """Given corrupted data (x at step t), compute x, denoised by one diffusion step,
        x_{t-1}.


        Args:
            xt (Tensor): uncorrupted data at step 0
            t (Tensor): diffusion step
            c (Optional[Dict[str, Tensor]]):
            cur_step Tensor:
            next_step Tensor:
            eta float:
        """
        # Model outputs
        alpha_bar = self.schedule("alphas_cumprod", cur_step, xt.shape)
        alpha_bar_next = self.schedule("alphas_cumprod", next_step, xt.shape)
        alpha_bar_next_sqred = self.schedule("sqrt_alphas_cumprod", next_step, xt.shape)

        out = self.model(xt, cur_step, c)
        pred = out.prediction

        x0 = self.predictor.predict_x0(pred, xt, cur_step)
        noise = self.schedule.sample_noise(xt)

        pred_noise = self.predictor.predict_noise(pred, xt, cur_step)

        sigma = (
            self.eta
            * (
                (1 - alpha_bar / alpha_bar_next)
                * (1 - alpha_bar_next)
                / (1 - alpha_bar)
            ).sqrt()
        )

        # Equation 12
        # In this equation, we use the predicted x_0, stochastic noise, and the
        # predicted noise to compute x_{t-1}.
        xt = (
            x0 * alpha_bar_next_sqred
            + sigma * noise
            # pyre-fixme
            + (((1 - alpha_bar_next) - torch.square(sigma)).sqrt()) * pred_noise
        ).to(dtype=xt.dtype)

        return xt

    def generator(
        self,
        x: Tensor,
        c: Optional[Dict[str, Tensor]] = None,
    ) -> Generator[Tensor, None, None]:
        """Generate xt for each t in self.eval_steps"""
        steps = self.eval_steps.flip(0)
        for step, next_step in zip(steps[:-1], steps[1:]):
            # Convert steps to batched tensors
            t = step * torch.ones(x.size(0), device=x.device, dtype=torch.long)
            t1 = next_step * torch.ones(x.size(0), device=x.device, dtype=torch.long)
            # Remove noise between step t and t+1
            x = self.remove_noise(x, c, t, t1)
            yield x

    def forward(
        self,
        x: Tensor,
        timestep: Optional[Tensor] = None,
        conditional_inputs: Optional[Dict[str, Tensor]] = None,
    ) -> Union[DiffusionOutput, Tensor]:
        if self.training:
            if timestep is None:
                raise ValueError("Must provide a timestep value during training")
            return self.model(x, timestep, conditional_inputs)
        else:
            gen: Iterable = self.generator(x, conditional_inputs)
            if self.progress_bar:
                # Lazy import so that we don't depend on tqdm.
                from tqdm.auto import tqdm

                gen = tqdm(gen, total=len(self.eval_steps) - 1)
            for x in gen:
                pass
            # pyre-ignore
            return x
