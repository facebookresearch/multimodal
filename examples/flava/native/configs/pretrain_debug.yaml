training:
  strategy: fsdp # can be changed to ddp or fsdp
  seed: 1337

  batch_size: 90
  num_workers: 10
  prefetch_factor: 2

  optimizer:
    learning_rate: 1e-3
    adam_eps: 1e-8
    adam_weight_decay: 0.1
    adam_betas: [0.9, 0.999]

  warmup_steps: 10000
  max_steps: 100000

  validation_steps: 500
  log_interval: 10

  enable_tf32: True
  enable_amp: True
  half_precision_format: "bfloat16"  # or float16
  enable_half_reduce_in_fsdp: True  # handles the reduction across devices in half precision

  activation_checkpointing: False
  activation_checkpointing_reentrant: False # false for non-reentrant

datasets:
  _target_: flava.definitions.TrainingDatasetsInfo
  selected:
  - image
  - vl
  - text
  image:
    _target_: flava.definitions.TrainingSingleDatasetInfo
    train:
      - _target_: flava.definitions.HFDatasetInfo
        key: imagenet-1k
        subset: default
  text:
    _target_: flava.definitions.TrainingSingleDatasetInfo
    train:
      - _target_: flava.definitions.HFDatasetInfo
        key: wikitext
        subset: wikitext-103-raw-v1
    datamodule_extra_kwargs:
      text_columns: ["text"]
  vl:
    _target_: flava.definitions.TrainingSingleDatasetInfo
    train:
      - _target_: flava.definitions.HFDatasetInfo
        key: red_caps
        subset: backpacking
        rename_columns:
          - ["caption", "text"]
    val:
      - _target_: flava.definitions.HFDatasetInfo
        key: red_caps
        subset: backpacking
        rename_columns:
          - ["caption", "text"]
        split_key_mapping:
          validation: train

model:
  size: 3b

  350m:
    image_num_hidden_layers: 12
    image_hidden_size: 768
    image_intermediate_size: 3072
    image_num_attention_heads: 12

    text_num_hidden_layers: 12
    text_hidden_size: 768
    text_intermediate_size: 3072
    text_num_attention_heads: 12

    multimodal_num_hidden_layers: 12
    multimodal_hidden_size: 768
    multimodal_intermediate_size: 3072
    multimodal_num_attention_heads: 12

    codebook_image_size: 8192
    hidden_size: 768

  900m:
    image_num_hidden_layers: 24
    image_hidden_size: 1024
    image_intermediate_size: 4096
    image_num_attention_heads: 16

    text_num_hidden_layers: 24
    text_hidden_size: 1024
    text_intermediate_size: 4096
    text_num_attention_heads: 16

    multimodal_num_hidden_layers: 24
    multimodal_hidden_size: 1024
    multimodal_intermediate_size: 4096
    multimodal_num_attention_heads: 16

    codebook_image_size: 8192
    hidden_size: 1024

  2b:
    image_num_hidden_layers: 32
    image_hidden_size: 1280
    image_intermediate_size: 5120
    image_num_attention_heads: 16

    text_num_hidden_layers: 32
    text_hidden_size: 1280
    text_intermediate_size: 5120
    text_num_attention_heads: 16

    multimodal_num_hidden_layers: 32
    multimodal_hidden_size: 1280
    multimodal_intermediate_size: 5120
    multimodal_num_attention_heads: 16

    codebook_image_size: 8192
    hidden_size: 1280

  3b:
    image_num_hidden_layers: 40
    image_hidden_size: 1408
    image_intermediate_size: 6144
    image_num_attention_heads: 16

    text_num_hidden_layers: 40
    text_hidden_size: 1408
    text_intermediate_size: 6144
    text_num_attention_heads: 16

    multimodal_num_hidden_layers: 40
    multimodal_hidden_size: 1408
    multimodal_intermediate_size: 6144
    multimodal_num_attention_heads: 16

    codebook_image_size: 8192
    hidden_size: 1408

  5b:
    image_num_hidden_layers: 48
    image_hidden_size: 1664
    image_intermediate_size: 8192
    image_num_attention_heads: 16

    text_num_hidden_layers: 48
    text_hidden_size: 1664
    text_intermediate_size: 8192
    text_num_attention_heads: 16

    multimodal_num_hidden_layers: 48
    multimodal_hidden_size: 1664
    multimodal_intermediate_size: 8192
    multimodal_num_attention_heads: 16

    codebook_image_size: 8192
    hidden_size: 1664

  10b:
    image_num_hidden_layers: 64
    image_hidden_size: 2048
    image_intermediate_size: 10240
    image_num_attention_heads: 16

    text_num_hidden_layers: 64
    text_hidden_size: 2048
    text_intermediate_size: 10240
    text_num_attention_heads: 16

    multimodal_num_hidden_layers: 64
    multimodal_hidden_size: 2048
    multimodal_intermediate_size: 10240
    multimodal_num_attention_heads: 16

    codebook_image_size: 8192
    hidden_size: 2048
